{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATb8D_Tp_hKs"
      },
      "source": [
        "# Synthesizing high-quality images from text descriptions\n",
        "Tanaya Joshi - tj2181"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fggBF8Zf_mXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30001cee-3968-49c9-d31b-3acbc3870d27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip /content/drive/MyDrive/gan/CUB_200_2011-20221225T213401Z-001.zip -d /content/drive/MyDrive/gan"
      ],
      "metadata": {
        "id": "wl5hMCq97ajV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/gan/birds.zip -d /content/drive/MyDrive/gan"
      ],
      "metadata": {
        "id": "xqOI-Cak94wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnczxE21oTqw"
      },
      "source": [
        "## Implementation of \"Stage 1 \" of **StackGAN**\n",
        "\n",
        "### Stage I of StackGAN \n",
        "\n",
        "#### 1- takes input as text, \n",
        "\n",
        "#### 2- convert the text to embedding using our pre-trained character level embedding. \n",
        "\n",
        "#### 3- Then, we give this embedding to Conditional Augmentation (CA) and \n",
        "\n",
        "#### 4- Pass output to Stage I Generator which gives us low-resolution 64*64 images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "StpwZzOYxFRo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"StackGAN.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
        "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rb4IqOBxN1C"
      },
      "source": [
        "\n",
        "\n",
        "# Conditioning Augmentation Network\n",
        "Finding the mean and covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SO_uUHnyxNOU"
      },
      "outputs": [],
      "source": [
        "# conditioned by the text.\n",
        "def conditioning_augmentation(x):\n",
        "\t\"\"\"The mean_logsigma passed as argument is converted into the text conditioning variable.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The output of the text embedding passed through a FC layer with LeakyReLU non-linearity.\n",
        "\n",
        "\tReturns:\n",
        "\t \tc: The text conditioning variable after computation.\n",
        "\t\"\"\"\n",
        "\tmean = x[:, :128]\n",
        "\tlog_sigma = x[:, 128:]\n",
        "\n",
        "\tstddev = tf.math.exp(log_sigma)\n",
        "\tepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
        "\tc = mean + stddev * epsilon\n",
        "\treturn c\n",
        "\n",
        "def build_ca_network():\n",
        "\t\"\"\"Builds the conditioning augmentation network.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
        "\tmls = Dense(256)(input_layer1)\n",
        "\tmls = LeakyReLU(alpha=0.2)(mls)\n",
        "\tca = Lambda(conditioning_augmentation)(mls)\n",
        "\treturn Model(inputs=[input_layer1], outputs=[ca]) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU1GU4Ds_hK1"
      },
      "source": [
        "\n",
        "# Stage 1 Generator Network \n",
        "\n",
        "1. The generator is fed with the text Embedding vectors which will be used to condition its generation of features.\n",
        "2. Concatinating the text embedding with noise from the gaussian distribution that is generated by the mean and variance values we found earlier. This will result in vector with random noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8BaEBiaCxFUd"
      },
      "outputs": [],
      "source": [
        "\n",
        "=\n",
        "def UpSamplingBlock(x, num_kernels):\n",
        "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The preceding layer as input.\n",
        "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
        "\n",
        "\tReturns:\n",
        "\t\tx: The final activation layer after the Upsampling block.\n",
        "\t\"\"\"\n",
        "\tx = UpSampling2D(size=(2,2))(x)\n",
        "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
        "\tx = ReLU()(x)\n",
        "\treturn x\n",
        "\n",
        "\n",
        "def build_stage1_generator():\n",
        "\n",
        "\tinput_layer1 = Input(shape=(1024,))\n",
        "\tca = Dense(256)(input_layer1)\n",
        "\tca = LeakyReLU(alpha=0.2)(ca)\n",
        "\n",
        "\t# Obtain the conditioned text\n",
        "\tc = Lambda(conditioning_augmentation)(ca)\n",
        "\n",
        "\tinput_layer2 = Input(shape=(100,))\n",
        "\tconcat = Concatenate(axis=1)([c, input_layer2]) \n",
        "\n",
        "\tx = Dense(16384, use_bias=False)(concat) \n",
        "\tx = ReLU()(x)\n",
        "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
        "\n",
        "\tx = UpSamplingBlock(x, 512) \n",
        "\tx = UpSamplingBlock(x, 256)\n",
        "\tx = UpSamplingBlock(x, 128)\n",
        "\tx = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3 \n",
        "\n",
        "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = Activation('tanh')(x)\n",
        "\n",
        "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
        "\treturn stage1_gen\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NR9rQp2Q_hK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9f459f-a310-4064-eaa1-6a96203c2465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          262400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 128)          0           ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 228)          0           ['lambda[0][0]',                 \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16384)        3735552     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 16384)        0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 4, 4, 1024)   0           ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 8, 8, 1024)   0           ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 8, 8, 512)    4718592     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 8, 8, 512)   2048        ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 8, 8, 512)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0          ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 256)  1179648     ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0          ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 128)  294912      ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0          ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 64)   73728       ['up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 3)    1728        ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 64, 3)    0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,270,400\n",
            "Trainable params: 10,268,480\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = build_stage1_generator()\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7hLipAxcXb"
      },
      "source": [
        "\n",
        "# Stage 1 Discriminator Network\n",
        "Tells if the image is fake or real\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JwHBP8sCxFXg"
      },
      "outputs": [],
      "source": [
        "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
        "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The preceding layer as input.\n",
        "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
        "\n",
        "\tReturns:\n",
        "\t\tx: The final activation layer after the ConvBlock block.\n",
        "\t\"\"\"\n",
        "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\t\n",
        "\tif activation:\n",
        "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\treturn x\n",
        "\n",
        "\n",
        "def build_embedding_compressor():\n",
        "    \"\"\"Build embedding compressor model\n",
        "    \"\"\"\n",
        "    input_layer1 = Input(shape=(1024,)) \n",
        "    x = Dense(128)(input_layer1)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer1], outputs=[x])\n",
        "    return model\n",
        "\n",
        "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
        "def build_stage1_discriminator():\n",
        "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
        "\tand the compressed and spatially replicated embedding.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 1 Discriminator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(64, 64, 3))  \n",
        "\n",
        "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
        "\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\tx = ConvBlock(x, 128)\n",
        "\tx = ConvBlock(x, 256)\n",
        "\tx = ConvBlock(x, 512)\n",
        "\n",
        "\t# Obtain the compressed and spatially replicated text embedding\n",
        "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
        "\tconcat = concatenate([x, input_layer2])\n",
        "\n",
        "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
        "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\t# Flatten and add a FC layer to predict.\n",
        "\tx1 = Flatten()(x1)\n",
        "\tx1 = Dense(1)(x1)\n",
        "\tx1 = Activation('sigmoid')(x1)\n",
        "\n",
        "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
        "\treturn stage1_dis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q0ruA2HM_hK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cd39fd-647e-48ba-9cd8-2110ea5a3ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 64)   3072        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 64)   0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 4, 4, 512)    2097152     ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 512)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            8193        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1)            0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,767,361\n",
            "Trainable params: 2,765,569\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = build_stage1_discriminator()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXNLnmkFxjI0"
      },
      "source": [
        "\n",
        "=\n",
        "# Stage 1 Adversarial Model  (Building a GAN)\n",
        "\n",
        "Generator and discriminator are stacked together. Output of the former is the input of the latter.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8rjVyqYhxFag"
      },
      "outputs": [],
      "source": [
        "# Building GAN with Generator and Discriminator\n",
        "\n",
        "def build_adversarial(generator_model, discriminator_model):\n",
        "\t\"\"\"Stage 1 Adversarial model.\n",
        "\n",
        "\tArgs:\n",
        "\t\tgenerator_model: Stage 1 Generator Model\n",
        "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
        "\n",
        "\tReturns:\n",
        "\t\tAdversarial Model.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,))  \n",
        "\tinput_layer2 = Input(shape=(100,)) \n",
        "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
        "\n",
        "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
        "\n",
        "\tdiscriminator_model.trainable = False \n",
        "\n",
        "\tprobabilities = discriminator_model([x, input_layer3]) \n",
        "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
        "\treturn adversarial_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gzbmPD21_hK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31d7ce6-f013-43a6-f77c-de3e37f84c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             [(None, 64, 64, 3),  10270400    ['input_5[0][0]',                \n",
            "                                 (None, 256)]                     'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, 1)            2767361     ['model[0][0]',                  \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,037,761\n",
            "Trainable params: 10,268,480\n",
            "Non-trainable params: 2,769,281\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "ganstage1 = build_adversarial(generator, discriminator)\n",
        "ganstage1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Dy_RuO42Am"
      },
      "source": [
        "\n",
        "# Train Utilities\n",
        "\n",
        "1. saving checkpoint\n",
        "2. save image \n",
        "3. calculating loss\n",
        "4. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuXx7HDj41XW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def checkpoint_prefix():\n",
        "\tcheckpoint_dir = './training_checkpoints'\n",
        "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "\n",
        "\treturn checkpoint_prefix\n",
        "\n",
        "def adversarial_loss(y_true, y_pred):\n",
        "\tmean = y_pred[:, :128]\n",
        "\tls = y_pred[:, 128:]\n",
        "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
        "\tloss = K.mean(loss)\n",
        "\treturn loss\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "\tinput_image = (input_image / 127.5) - 1\n",
        "\treal_image = (real_image / 127.5) - 1\n",
        "\n",
        "\treturn input_image, real_image\n",
        "\n",
        "def load_class_ids_filenames(class_id_path, filename_path):\n",
        "\twith open(class_id_path, 'rb') as file:\n",
        "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
        "\n",
        "\twith open(filename_path, 'rb') as file:\n",
        "\t\tfilename = pickle.load(file, encoding='latin1')\n",
        "\n",
        "\treturn class_id, filename\n",
        "\n",
        "def load_text_embeddings(text_embeddings):\n",
        "\twith open(text_embeddings, 'rb') as file:\n",
        "\t\tembeds = pickle.load(file, encoding='latin1')\n",
        "\t\tembeds = np.array(embeds)\n",
        "\n",
        "\treturn embeds\n",
        "\n",
        "def load_bbox(data_path):\n",
        "\tbbox_path = data_path + '/bounding_boxes.txt'\n",
        "\timage_path = data_path + '/images.txt'\n",
        "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
        "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
        "\n",
        "\tfilenames = filename_df[1].tolist()\n",
        "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
        "\n",
        "\tfor i in range(0, len(filenames)):\n",
        "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
        "\t\tdict_key = filenames[i][:-4]\n",
        "\t\tbbox_dict[dict_key] = bbox\n",
        "\n",
        "\treturn bbox_dict\n",
        "\n",
        "def load_images(image_path, bounding_box, size):\n",
        "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
        "\t\"\"\"\n",
        "\timage = Image.open(image_path).convert('RGB')\n",
        "\tw, h = image.size\n",
        "\tif bounding_box is not None:\n",
        "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
        "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
        "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
        "\t\ty1 = np.maximum(0, c_y - r)\n",
        "\t\ty2 = np.minimum(h, c_y + r)\n",
        "\t\tx1 = np.maximum(0, c_x - r)\n",
        "\t\tx2 = np.minimum(w, c_x + r)\n",
        "\t\timage = image.crop([x1, y1, x2, y2])\n",
        "\n",
        "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
        "\treturn image\n",
        "\n",
        "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
        "\t\"\"\"Loads the Dataset.\n",
        "\t\"\"\"\n",
        "\tdata_dir = \"/content/drive/MyDrive/gan/birds\"\n",
        "\ttrain_dir = data_dir + \"/train\"\n",
        "\ttest_dir = data_dir + \"/test\"\n",
        "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
        "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
        "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
        "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
        "\tdataset_path = \"/content/drive/MyDrive/gan/CUB_200_2011/CUB_200_2011\"\n",
        "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
        "\tembeddings = load_text_embeddings(embeddings_path)\n",
        "\tbbox_dict = load_bbox(dataset_path)\n",
        "\tx, y, embeds = [], [], []\n",
        "\n",
        "\tfor i, filename in enumerate(filenames):\n",
        "\t\tbbox = bbox_dict[filename]\n",
        "\n",
        "\t\ttry:\t\n",
        "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
        "\t\t\timage = load_images(image_path, bbox, size)\n",
        "\t\t\te = embeddings[i, :, :]\n",
        "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
        "\t\t\tembed = e[embed_index, :]\n",
        "\n",
        "\t\t\tx.append(np.array(image))\n",
        "\t\t\ty.append(class_id[i])\n",
        "\t\t\tembeds.append(embed)\n",
        "\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(f'{e}')\n",
        "\t\n",
        "\tx = np.array(x)\n",
        "\ty = np.array(y)\n",
        "\tembeds = np.array(embeds)\n",
        "\t\n",
        "\treturn x, y, embeds\n",
        "\n",
        "def save_image(file, save_path):\n",
        "\t\"\"\"Saves the image at the specified file path.\n",
        "\t\"\"\"\n",
        "\timage = plt.figure()\n",
        "\tax = image.add_subplot(1,1,1)\n",
        "\tax.imshow(file)\n",
        "\tax.axis(\"off\")\n",
        "\tplt.savefig(save_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining and training the Stage 1 model\n",
        "1. training for 120 epochs. The paper says to train for 600 epcohs."
      ],
      "metadata": {
        "id": "9qWcUp7DLozi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pjcH1V8ax9A1"
      },
      "outputs": [],
      "source": [
        "\n",
        "############################################################\n",
        "# StackGAN class\n",
        "############################################################\n",
        "data_dir = \"/content/drive/MyDrive/gan/birds\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "test_dir = data_dir + \"/test\"\n",
        "embeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "embeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "filename_path_train = train_dir + \"/filenames.pickle\"\n",
        "filename_path_test = test_dir + \"/filenames.pickle\"\n",
        "class_id_path_train = train_dir + \"/class_info.pickle\"\n",
        "class_id_path_test = test_dir + \"/class_info.pickle\"\n",
        "dataset_path = \"/content/drive/MyDrive/gan/CUB_200_2011/CUB_200_2011\"\n",
        "class StackGanStage1(object):\n",
        "  \"\"\"StackGAN Stage 1 class.\"\"\"\n",
        "  def __init__(self, epochs=120, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
        "    self.epochs = epochs\n",
        "    self.z_dim = z_dim\n",
        "    self.enable_function = enable_function\n",
        "    self.stage1_generator_lr = stage1_generator_lr\n",
        "    self.stage1_discriminator_lr = stage1_discriminator_lr\n",
        "    self.image_size = 64\n",
        "    self.conditioning_dim = 128\n",
        "    self.batch_size = batch_size\n",
        "    self.gen_loss = []\n",
        "    self.dis_loss = [] \n",
        "    self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "    self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "        \n",
        "    self.stage1_generator = build_stage1_generator()\n",
        "    self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
        "\n",
        "    self.stage1_discriminator = build_stage1_discriminator()\n",
        "    self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
        "\n",
        "    self.ca_network = build_ca_network()\n",
        "    self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "    self.embedding_compressor = build_embedding_compressor()\n",
        "    self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "    self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
        "    self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
        "\n",
        "    self.checkpoint1 = tf.train.Checkpoint(\n",
        "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
        "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
        "        \tgenerator=self.stage1_generator,\n",
        "        \tdiscriminator=self.stage1_discriminator)\n",
        "\n",
        "  def visualize_stage1(self):\n",
        "    \"\"\"Running Tensorboard visualizations.\"\"\"\n",
        "    tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "    tb.set_model(self.stage1_generator)\n",
        "    tb.set_model(self.stage1_discriminator)\n",
        "    tb.set_model(self.ca_network)\n",
        "    tb.set_model(self.embedding_compressor)\n",
        "\n",
        "  def train_stage1(self):\n",
        "    \"\"\"Trains the stage1 StackGAN.\"\"\"\n",
        "    x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
        "\n",
        "    x_test, y_test, test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
        "       dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
        "\n",
        "    real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
        "    fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      print(f'Epoch: {epoch}')\n",
        "      num_batches = int(x_train.shape[0] / self.batch_size)\n",
        "\n",
        "      for i in range(num_batches):\n",
        "\n",
        "        latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "        embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "        compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
        "        compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
        "        compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
        "\n",
        "        image_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
        "        image_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "        gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
        "\n",
        "        discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
        "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
        "\n",
        "        discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
        "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
        "\n",
        "        discriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], compressed_embedding[1:]], \n",
        "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
        "\n",
        "\t\t    # Discriminator loss\n",
        "        d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
        "        self.dis_loss.append(d_loss)\n",
        "\n",
        "        print(f'Discriminator Loss: {d_loss}')\n",
        "\n",
        "\t\t    # Generator loss\n",
        "        g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
        "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
        "\n",
        "        print(f'Generator Loss: {g_loss}')\n",
        "        self.gen_loss.append(g_loss)\n",
        "\n",
        "        # if epoch % 5 == 0:\n",
        "        #     latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "        #     embedding_batch = test_embeds[0 : self.batch_size]\n",
        "        #     gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
        "\n",
        "        #     for i, image in enumerate(gen_images[:10]):\n",
        "        #         save_image(image, f'/content/drive/MyDrive/gan/test/gen_1_{epoch}_{i}')\n",
        "\n",
        "        if epoch % 25 == 0:\n",
        "          self.stage1_generator.save_weights('/content/drive/MyDrive/gan/weights/stage1_gen.h5')\n",
        "          self.stage1_discriminator.save_weights(\"/content/drive/MyDrive/gan/weights/stage1_disc.h5\")\n",
        "          self.ca_network.save_weights('/content/drive/MyDrive/gan/weights/stage1_ca.h5')\n",
        "          self.embedding_compressor.save_weights('/content/drive/MyDrive/gan/weights/stage1_embco.h5')\n",
        "          self.stage1_adversarial.save_weights('/content/drive/MyDrive/gan/weights/stage1_adv.h5')      \n",
        "\n",
        "    self.stage1_generator.save_weights('/content/drive/MyDrive/gan/weights/stage1_gen.h5')\n",
        "    self.stage1_discriminator.save_weights(\"/content/drive/MyDrive/gan/weights/stage1_disc.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WUDlLFK0xFdV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "d4994fbc-509d-4547-8ca3-a99ace753bfa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-34644e9acffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackGanStage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c5ad002fbcd4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, z_dim, batch_size, enable_function, stage1_generator_lr, stage1_discriminator_lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1_generator_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage1_generator_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1_discriminator_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage1_discriminator_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
          ]
        }
      ],
      "source": [
        "stage1 = StackGanStage1()\n",
        "stage1.train_stage1()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = stage1.gen_loss\n",
        "discriminator= stage1.disc_loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(discriminator)\n",
        "plt.xlabel(\"discriminator_loss\")\n",
        "plt.ylabel(\"epochs\") \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jdU59XtvIXQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inj5IwROxFgE"
      },
      "source": [
        "## Check test folder for gernerated images from Stage1 Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxZNAwt_hK6"
      },
      "source": [
        "##Stage 2 Generator\n",
        "1. Conditioning Augmentation\n",
        "2. Downsampling \n",
        "3. Residual blocks\n",
        "4. Upsampling\n",
        "5. Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp-wjDCj_hK6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import LeakyReLU\n",
        "def concat_along_dims(inputs):\n",
        "\t\"\"\"Joins the conditioned text with the encoded image along the dimensions.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinputs: consisting of conditioned text and encoded images as [c,x].\n",
        "\n",
        "\tReturns:\n",
        "\t\tJoint block along the dimensions.\n",
        "\t\"\"\"\n",
        "\tc = inputs[0]\n",
        "\tx = inputs[1]\n",
        "\n",
        "\tc = K.expand_dims(c, axis=1)\n",
        "\tc = K.expand_dims(c, axis=1)\n",
        "\tc = K.tile(c, [1, 16, 16, 1])\n",
        "\treturn K.concatenate([c, x], axis = 3)\n",
        "\n",
        "def residual_block(input):\n",
        "\t\"\"\"Residual block with plain identity connections.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinputs: input layer or an encoded layer\n",
        "\n",
        "\tReturns:\n",
        "\t\tLayer with computed identity mapping.\n",
        "\t\"\"\"\n",
        "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\t\n",
        "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\t\n",
        "\tx = add([x, input])\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\treturn x\n",
        "\n",
        "def build_stage2_generator():\n",
        "\t\"\"\"Build the Stage 2 Generator Network using the conditioning text and images from stage 1.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Generator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,))\n",
        "\tinput_images = Input(shape=(64, 64, 3))\n",
        "\n",
        "\t# Conditioning Augmentation\n",
        "\tca = Dense(256)(input_layer1)\n",
        "\tmls = LeakyReLU(alpha=0.2)(ca)\n",
        "\tc = Lambda(conditioning_augmentation)(mls)\n",
        "\n",
        "\t# Downsampling block\n",
        "\tx = ZeroPadding2D(padding=(1,1))(input_images)\n",
        "\tx = Conv2D(128, kernel_size=(3,3), strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
        "\tx = Conv2D(256, kernel_size=(4,4), strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
        "\tx = Conv2D(512, kernel_size=(4,4), strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\t# Concatenate text conditioning block with the encoded image\n",
        "\tconcat = concat_along_dims([c, x])\n",
        "\n",
        "\t# Residual Blocks\n",
        "\tx = ZeroPadding2D(padding=(1,1))(concat)\n",
        "\tx = Conv2D(512, kernel_size=(3,3), use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\n",
        "\t# Upsampling Blocks\n",
        "\tx = UpSamplingBlock(x, 512)\n",
        "\tx = UpSamplingBlock(x, 256)\n",
        "\tx = UpSamplingBlock(x, 128)\n",
        "\tx = UpSamplingBlock(x, 64)\n",
        "\n",
        "\tx = Conv2D(3, kernel_size=(3,3), padding='same', use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "\tx = Activation('tanh')(x)\n",
        "\t\n",
        "\tstage2_gen = Model(inputs=[input_layer1, input_images], outputs=[x, mls])\n",
        "\treturn stage2_gen\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAXJjXQQ_hK6"
      },
      "outputs": [],
      "source": [
        "generator_stage2 = build_stage2_generator()\n",
        "generator_stage2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpCrEbJ8_hK6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Stage 2 Discriminator Network\n",
        "\n",
        "\n",
        "def build_stage2_discriminator():\n",
        "\t\"\"\"Builds the Stage 2 Discriminator that uses the 256x256 resolution images from the generator\n",
        "\tand the compressed and spatially replicated embeddings.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Discriminator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(256, 256, 3))\n",
        "\n",
        "\tx = Conv2D(64, kernel_size=(4,4), padding='same', strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
        "\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\tx = ConvBlock(x, 128)\n",
        "\tx = ConvBlock(x, 256)\n",
        "\tx = ConvBlock(x, 512)\n",
        "\tx = ConvBlock(x, 1024)\n",
        "\tx = ConvBlock(x, 2048)\n",
        "\tx = ConvBlock(x, 1024, (1,1), 1)\n",
        "\tx = ConvBlock(x, 512, (1,1), 1, False)\n",
        "\n",
        "\tx1 = ConvBlock(x, 128, (1,1), 1)\n",
        "\tx1 = ConvBlock(x1, 128, (3,3), 1)\n",
        "\tx1 = ConvBlock(x1, 512, (3,3), 1, False)\n",
        "\n",
        "\tx2 = add([x, x1])\n",
        "\tx2 = LeakyReLU(alpha=0.2)(x2)\n",
        "\n",
        "\t# Concatenate compressed and spatially replicated embedding\n",
        "\tinput_layer2 = Input(shape=(4, 4, 128))\n",
        "\tconcat = concatenate([x2, input_layer2])\n",
        "\n",
        "\tx3 = Conv2D(512, kernel_size=(1,1), strides=1, padding='same', kernel_initializer='he_uniform')(concat)\n",
        "\tx3 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x3)\n",
        "\tx3 = LeakyReLU(alpha=0.2)(x3)\n",
        "\n",
        "\t# Flatten and add a FC layer\n",
        "\tx3 = Flatten()(x3)\n",
        "\tx3 = Dense(1)(x3)\n",
        "\tx3 = Activation('sigmoid')(x3)\n",
        "\n",
        "\tstage2_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x3])\n",
        "\treturn stage2_dis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THtXl8yM_hK7"
      },
      "outputs": [],
      "source": [
        "discriminator_stage2 = build_stage2_discriminator()\n",
        "discriminator_stage2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKTWi6s8_hK7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Stage 2 Adversarial Model\n",
        "\n",
        "\n",
        "def stage2_adversarial_network(stage2_disc, stage2_gen, stage1_gen):\n",
        "\t\"\"\"Stage 2 Adversarial Network.\n",
        "\n",
        "\tArgs:\n",
        "\t\tstage2_disc: Stage 2 Discriminator Model.\n",
        "\t\tstage2_gen: Stage 2 Generator Model.\n",
        "\t\tstage1_gen: Stage 1 Generator Model.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Adversarial network.\n",
        "\t\"\"\"\n",
        "\tconditioned_embedding = Input(shape=(1024, ))\n",
        "\tlatent_space = Input(shape=(100, ))\n",
        "\tcompressed_replicated = Input(shape=(4, 4, 128))\n",
        "    \n",
        "\t#the discriminator is trained separately and stage1_gen already trained, and this is the reason why we freeze its layers by setting the property trainable=false\n",
        "\tinput_images, ca = stage1_gen([conditioned_embedding, latent_space])\n",
        "\tstage2_disc.trainable = False\n",
        "\tstage1_gen.trainable = False\n",
        "\n",
        "\timages, ca2 = stage2_gen([conditioned_embedding, input_images])\n",
        "\tprobability = stage2_disc([images, compressed_replicated])\n",
        "\n",
        "\treturn Model(inputs=[conditioned_embedding, latent_space, compressed_replicated],\n",
        "\t\toutputs=[probability, ca2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oDsyjDW_hK7"
      },
      "outputs": [],
      "source": [
        "adversarial_stage2 = stage2_adversarial_network(discriminator_stage2, generator_stage2, generator)\n",
        "adversarial_stage2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkfWQUmz_hK7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class StackGanStage2(object):\n",
        "\t\"\"\"StackGAN Stage 2 class.\n",
        "\n",
        "\tArgs:\n",
        "\t\tepochs: Number of epochs\n",
        "\t\tz_dim: Latent space dimensions\n",
        "\t\tbatch_size: Batch Size\n",
        "\t\tenable_function: If True, training function is decorated with tf.function\n",
        "\t\tstage2_generator_lr: Learning rate for stage 2 generator\n",
        "\t\tstage2_discriminator_lr: Learning rate for stage 2 discriminator\n",
        "\t\"\"\"\n",
        "\t#batch size should be 64 making it 16 due to memory issue\n",
        "\tdef __init__(self, epochs=80, z_dim=100, batch_size=64, enable_function=True, stage2_generator_lr=0.0002, stage2_discriminator_lr=0.0002):\n",
        "\t\tself.epochs = epochs\n",
        "\t\tself.z_dim = z_dim\n",
        "\t\tself.enable_function = enable_function\n",
        "\t\tself.stage1_generator_lr = stage2_generator_lr\n",
        "\t\tself.stage1_discriminator_lr = stage2_discriminator_lr\n",
        "\t\tself.low_image_size = 64\n",
        "\t\tself.high_image_size = 256\n",
        "\t\tself.conditioning_dim = 128\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\t\n",
        "\t\tself.gen_loss = []\n",
        "\t\tself.disc_loss = []\n",
        "\t\tself.stage2_generator_optimizer = Adam(lr=stage2_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\t\tself.stage2_discriminator_optimizer = Adam(lr=stage2_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\t\tself.stage1_generator = build_stage1_generator()\n",
        "\t\tself.stage1_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
        "\t\tself.stage1_generator.load_weights('/content/drive/MyDrive/gan/weights/stage1_gen.h5')\n",
        "\t\tself.stage2_generator = build_stage2_generator()\n",
        "\t\tself.stage2_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
        "\n",
        "\t\tself.stage2_discriminator = build_stage2_discriminator()\n",
        "\t\tself.stage2_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage2_discriminator_optimizer)\n",
        "\n",
        "\t\tself.ca_network = build_ca_network()\n",
        "\t\tself.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t\tself.embedding_compressor = build_embedding_compressor()\n",
        "\t\tself.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t\tself.stage2_adversarial = stage2_adversarial_network(self.stage2_discriminator, self.stage2_generator, self.stage1_generator)\n",
        "\t\tself.stage2_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage2_generator_optimizer)\t\n",
        "\n",
        "\t\tself.checkpoint2 = tf.train.Checkpoint(\n",
        "        \tgenerator_optimizer=self.stage2_generator_optimizer,\n",
        "        \tdiscriminator_optimizer=self.stage2_discriminator_optimizer,\n",
        "        \tgenerator=self.stage2_generator,\n",
        "        \tdiscriminator=self.stage2_discriminator,\n",
        "        \tgenerator1=self.stage1_generator)\n",
        "\n",
        "\tdef visualize_stage2(self):\n",
        "\t\t\"\"\"Running Tensorboard visualizations.\n",
        "\t\t\"\"\"\n",
        "\t\ttb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "\t\ttb.set_model(self.stage2_generator)\n",
        "\t\ttb.set_model(self.stage2_discriminator)\n",
        "\n",
        "\tdef train_stage2(self):\n",
        "\t\t\"\"\"Trains Stage 2 StackGAN.\n",
        "\t\t\"\"\"\n",
        "\t\tx_high_train, y_high_train, high_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(256, 256))\n",
        "\n",
        "\t\tx_high_test, y_high_test, high_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(256, 256))\n",
        "\n",
        "\t\tx_low_train, y_low_train, low_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
        "\n",
        "\t\tx_low_test, y_low_test, low_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
        "\n",
        "\t\treal = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
        "\t\tfake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
        "\n",
        "\t\tfor epoch in range(self.epochs):\n",
        "\t\t\tprint(f'Epoch: {epoch}')\n",
        "\n",
        "\n",
        "\t\t\tnum_batches = int(x_high_train.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\tfor i in range(num_batches):\n",
        "\n",
        "\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "\t\t\t\tembedding_text = high_train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "\t\t\t\tcompressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
        "\t\t\t\tcompressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, self.conditioning_dim))\n",
        "\t\t\t\tcompressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
        "\n",
        "\t\t\t\timage_batch = x_high_train[i * self.batch_size:(i+1) * self.batch_size]\n",
        "\t\t\t\timage_batch = (image_batch - 127.5) / 127.5\n",
        "\t\t\t\t\n",
        "\t\t\t\tlow_res_fakes, _ = self.stage1_generator.predict([embedding_text, latent_space], verbose=3)\n",
        "\t\t\t\thigh_res_fakes, _ = self.stage2_generator.predict([embedding_text, low_res_fakes], verbose=3)\n",
        "\n",
        "\t\t\t\tdiscriminator_loss = self.stage2_discriminator.train_on_batch([image_batch, compressed_embedding],\n",
        "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
        "\n",
        "\t\t\t\tdiscriminator_loss_gen = self.stage2_discriminator.train_on_batch([high_res_fakes, compressed_embedding],\n",
        "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
        "\n",
        "\t\t\t\tdiscriminator_loss_fake = self.stage2_discriminator.train_on_batch([image_batch[:(self.batch_size-1)], compressed_embedding[1:]],\n",
        "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size - 1, 1)))\n",
        "\n",
        "\t\t\t\td_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_fake))\n",
        "\t\t\t\tself.disc_loss.append(d_loss)\n",
        "\n",
        "\t\t\t\tprint(f'Discriminator Loss: {d_loss}')\n",
        "\n",
        "\t\t\t\tg_loss = self.stage2_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
        "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
        "\t\t\t\tself.gen_loss.append(g_loss)\n",
        "\n",
        "\t\t\t\tprint(f'Generator Loss: {g_loss}')\n",
        "\n",
        "\t\t\t\tif epoch % 5 == 0:\n",
        "\t\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "\t\t\t\t\tembedding_batch = high_test_embeds[0 : self.batch_size]\n",
        "\n",
        "\t\t\t\t\tlow_fake_images, _ = self.stage1_generator.predict([embedding_batch, latent_space], verbose=3)\n",
        "\t\t\t\t\thigh_fake_images, _ = self.stage2_generator.predict([embedding_batch, low_fake_images], verbose=3)\n",
        "\t\t\t\t\tfor i, image in enumerate(high_fake_images[:10]):\n",
        "\t\t\t\t\t\tsave_image(image, f'/content/drive/MyDrive/gan/results_stage2/gen_high_{epoch}_{i}.png')\n",
        "\t\t\t\tif epoch%10==0:\n",
        "\t\t\t\t\tself.stage2_generator.save_weights('/content/drive/MyDrive/gan/weights/stage2_gen.h5')\n",
        "\t\t\t\t\tself.stage2_discriminator.save_weights(\"/content/drive/MyDrive/gan/weights/stage2_disc.h5\")\n",
        "\t\t\t\t\tself.ca_network.save_weights('/content/drive/MyDrive/gan/weights/stage2_ca.h5')\n",
        "\t\t\t\t\tself.embedding_compressor.save_weights('/content/drive/MyDrive/gan/weights/stage2_embco.h5')\n",
        "\t\t\t\t\tself.stage2_adversarial.save_weights('/content/drive/MyDrive/gan/weights/stage2_adv.h5')\n",
        "\t\t\n",
        "\t\t\tself.stage2_generator.save_weights('/content/drive/MyDrive/gan/weights/stage2_gen.h5')\n",
        "\t\t\tself.stage2_discriminator.save_weights(\"/content/drive/MyDrive/gan/weights/stage2_disc.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi994abM_hK7"
      },
      "outputs": [],
      "source": [
        "\n",
        "stage2 = StackGanStage2()\n",
        "stage2.train_stage2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njec8wd1_hK8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(stage2.disc_loss)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"discriminator loss\") \n",
        "plt.show()\n",
        "plt.plot(stage2.gen_loss)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"generator loss\")  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nakoj_pwaFwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}